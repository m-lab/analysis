{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather all raw data files associated with a particular UUID\n",
    "(Using unified tables)\n",
    "\n",
    "Steps:\n",
    "\n",
    "- Fetch the row from BQ and extract:\n",
    "  - GCS file name. Extract from the name:\n",
    "    - Server shortname\n",
    "    - Pusher datestring and timestamp\n",
    "    - Check if the date is too old\n",
    "  - From the row array, constrct tcpinfo tsg annotations\n",
    "  - Fetch the raw file\n",
    "- mkdir UUID\n",
    "- gsutil ls pcap path using pusher datestring and shortname\n",
    "- Select and fetch likely file (slightly earlier than ndt5 pusher timestamp)\n",
    "- system tar tvf and search UUID to find full path and file name\n",
    "- Extract file, mv to target dir and rmdir extras\n",
    "- tcptrace to extract xplots\n",
    "- Merge tcpinfo tsg annotations w/ b2a_tsg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import math\n",
    "import pandas as pd\n",
    "import BQhelper as bq\n",
    "from google.cloud import storage\n",
    "\n",
    "DataDir='/data/'  # Typically mounted at $HOME/data/\n",
    "TarDir=DataDir+'TARFILES/'\n",
    "os.makedirs(TarDir, exist_ok=True)\n",
    "\n",
    "UnitTest = True\n",
    "Verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CASES.    These are manually curated points of interst\n",
    "UUID1=\"ndt-r5mmc_1572346210_00000000000142D4\"\n",
    "# 2019-12-12 72.208.51.92 AZ\n",
    "# SELECT * FROM `mlab-sandbox.mm_unified_testing.ndt_unified_ndt5_downloads` WHERE a.UUID = 'ndt-r5mmc_1572346210_00000000000142D4'\n",
    "# gs://archive-measurement-lab/ndt/ndt5/2019/12/12/20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\n",
    "# gs://archive-measurement-lab/ndt/tcpinfo/2019/12/12/20191212T172147.966587Z-tcpinfo-mlab2-lax06-ndt.tgz\n",
    "# \n",
    "\n",
    "# Deep dive into 80.0.65.231, after the trasnsition\n",
    "# See row 901 in 2020-04-25 Dissect 80.0.65.231across transition (adjust limits)\n",
    "# 2019-12-28 07:37:54.054766 UTC\n",
    "UUID2=\"ndt-m92kv_1573028939_0000000000056D7A\"\n",
    "\n",
    "# Deep dive into Mirakami NDT7\n",
    "# Anomalous performance for 205.153.50.1\n",
    "\n",
    "UUID3='ndt-qnzxt_1589228170_00000000000F556B'  # NOPE - this is NDT7\n",
    "UUID4='ndt-567fj_1589322458_00000000000B9A29'\n",
    "if UnitTest:\n",
    "    Tuuid = UUID4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://archive-measurement-lab/ndt/ndt5/2019/12/12/20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\n",
      "FullName ndt/ndt5/2019/12/12/20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\n",
      "Dir ndt/ndt5/2019/12/12\n",
      "File 20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\n",
      "Date 2019-12-12\n",
      "Time 20191212T160135\n",
      "ShortNane mlab2-lax06\n"
     ]
    }
   ],
   "source": [
    "# Helper functions to parse a pusher data file names\n",
    "\n",
    "if UnitTest:\n",
    "    pf=\"gs://archive-measurement-lab/ndt/ndt5/2019/12/12/20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\"\n",
    "\n",
    "def parseFullName(pf):\n",
    "    \"\"\"Parse the full name from an archived pusher tar file name\n",
    "    e.g. ndt/ndt5/2019/12/12/20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\n",
    "    \"\"\"   \n",
    "    return('/'.join(pf.split('/')[3:]))\n",
    "\n",
    "def parseDir(pf):\n",
    "    \"\"\"Parse the gcs directory from an archived pusher tar file name\n",
    "    e.g. ndt/ndt5/2019/12/12/\n",
    "    \"\"\"\n",
    "    return('/'.join(pf.split('/')[3:-1]))\n",
    "\n",
    "def parseFile(pf):\n",
    "    \"\"\"Parse the gcs file from an archived pusher tar file name\n",
    "    e.g. 20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\n",
    "    \"\"\"\n",
    "    return(pf.split('/')[-1])\n",
    "\n",
    "def parseDate(pf):\n",
    "    \"\"\"Parse and reformat the archive date from a pusher tar file name\n",
    "    e.g. 2019-12-12 (NB: this is NOT the test date)\n",
    "    \"\"\"\n",
    "    return('-'.join(pf.split('/')[-4:-1]))\n",
    "\n",
    "def parseTime(pf):\n",
    "    \"\"\"Parse the timestamp from an archived pusher tar file name\n",
    "    e.g. 20191212T160135\n",
    "    \"\"\"\n",
    "    return(pf.split('/')[-1].split('.')[0])\n",
    "    \n",
    "def parseShortName(pf):\n",
    "    \"\"\"Parse the server shortname from an archived pusher tar file name\n",
    "    e.g. mlab2-lax06\n",
    "    \"\"\"\n",
    "    return('-'.join(pf.split('-')[-3:-1]))\n",
    "\n",
    "if UnitTest:\n",
    "    print(pf)\n",
    "    print('FullName', parseFullName(pf))\n",
    "    print('Dir', parseDir(pf))\n",
    "    print('File', parseFile(pf))\n",
    "    print('Date', parseDate(pf))\n",
    "    print('Time', parseTime(pf))\n",
    "    print('ShortNane', parseShortName(pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://archive-measurement-lab/ndt/ndt5/2020/06/02/20200602T051452.620086Z-ndt5-mlab1-sea02-ndt.tgz\n",
      "['ndt-567fj_1589322458_00000000000B9A19', 'ndt-567fj_1589322458_00000000000B9A29', 'ndt-567fj_1589322458_00000000000B9A17']\n"
     ]
    }
   ],
   "source": [
    "# Find all the Details for any given UUID\n",
    "# Including other UUIDs assocated with the same test\n",
    "# and all gcs paths.\n",
    "\n",
    "# TODO: BUG how to generalize\n",
    "\n",
    "QueryDetails=\"\"\"\n",
    "SELECT\n",
    "  ParseInfo.TaskFileName,\n",
    "  result.C2S.UUID AS c2sUUID,\n",
    "  result.S2C.UUID AS s2cUUID,\n",
    "#  result.Upload.UUID AS uploadUUID,\n",
    "#  result.Download.UUID AS downloadUUID,\n",
    "  result.Control.UUID AS controlUUID,\n",
    "FROM `mlab-oti.ndt.ndt5`\n",
    "WHERE\n",
    "  result.C2S.UUID = '{UUID}' OR\n",
    "  result.S2C.UUID = '{UUID}' OR\n",
    "#  result.Upload.UUID = '{UUID}' OR\n",
    "#  result.Download.UUID = '{UUID}' OR\n",
    "  result.Control.UUID = '{UUID}'\n",
    "\"\"\"\n",
    "\n",
    "def getTestDetails(uuid):\n",
    "    \"\"\"Get details on where to find raw data associated with a test UUID\n",
    "    Returns:\n",
    "        the location of the primary raw data in gcs; and\n",
    "        a list of connection UUIDs associated wiht the test.\n",
    "        BUG: Needs to be generalized for other tables\n",
    "    \"\"\"\n",
    "    q=bq.run_query(QueryDetails, UUID=uuid)\n",
    "    if (len(q['TaskFileName'])) != 1:\n",
    "            print(\"Warning: getTestDetails: (%d)\"%len(q['TaskFileName']))\n",
    "            return(None, None)\n",
    "    ret=[]\n",
    "    for c in ['c2sUUID', 's2cUUID', 'controlUUID']:\n",
    "        if (q[c][0] is not None\n",
    "            and q[c][0] not in ret):\n",
    "                ret.append(q[c][0])\n",
    "        \n",
    "    return(q['TaskFileName'][0], ret)\n",
    "\n",
    "\n",
    "# Minimal test:\n",
    "if UnitTest:\n",
    "    TtaskFile, T_UUIDs = getTestDetails(Tuuid)\n",
    "    print (TtaskFile)\n",
    "    # gs://archive-measurement-lab/ndt/ndt5/2019/12/28/20191228T080102.072817Z-ndt5-mlab1-lhr04-ndt.tgz\n",
    "    print (T_UUIDs) # ['ndt-m92kv_1573028939_0000000000056D7A', 'ndt-m92kv_1573028939_0000000000056D78']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndt/ndt5/2020/06/02\n",
      "9888\n"
     ]
    }
   ],
   "source": [
    "def listArchive(path):\n",
    "    \"\"\"List the files in a given GCS path\n",
    "    \"\"\"\n",
    "    client = storage.Client(project='mlab-sandbox')\n",
    "    bucket = client.get_bucket('archive-measurement-lab')\n",
    "    r = bucket.list_blobs(prefix=path)\n",
    "    return [i.name for i in r]\n",
    "\n",
    "# Minimal test\n",
    "if UnitTest:\n",
    "    T_archive = '/'.join(TtaskFile.split('/')[3:-1])\n",
    "    print (T_archive) # ndt/ndt5/2019/12/28\n",
    "    blobs = listArchive(T_archive)\n",
    "    print(len(blobs)) # 4947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndt/ndt5/2020/06/02/20200602T051452.620086Z-ndt5-mlab1-sea02-ndt.tgz\n"
     ]
    }
   ],
   "source": [
    "# Fetch an GCS Blob from the MLab archive\n",
    "# TODO: Add support for non-production archives\n",
    "\n",
    "def fetchBlob(blob, dest, bucket='archive-measurement-lab'):\n",
    "    \"\"\"Fetch a blob of data gsc\n",
    "    NB: blob excludes the bucket: e.g. 'gs://archive-measurement-lab/'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.stat(dest)\n",
    "        return True\n",
    "    except:\n",
    "        pass\n",
    "    client = storage.Client(project='mlab-sandbox')\n",
    "    bucket = client.get_bucket(bucket)\n",
    "    blob = bucket.get_blob(blob)\n",
    "    with open(dest, 'wb') as file_obj:\n",
    "        client.download_blob_to_file(blob, file_obj)\n",
    "\n",
    "# Minimal test\n",
    "if UnitTest:\n",
    "    t = '/'.join(TtaskFile.split('/')[3:])\n",
    "    print(t)\n",
    "    # ndt/ndt5/2019/12/28/20191228T080102.072817Z-ndt5-mlab1-lhr04-ndt.tgz\n",
    "    Ttarfile = TarDir+'/test.ndt5.tgz'\n",
    "    fetchBlob(t, Ttarfile)\n",
    "    # Check for test.ndt5.tgz in TarDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndt-567fj_1589322458_00000000000B9A19\n",
      "[]\n",
      "Found: 2020/06/02/ndt-567fj_1589322458_00000000000B9A17.json\n",
      "['2020/06/02/ndt-567fj_1589322458_00000000000B9A17.json']\n",
      "['tar', '--extract', '-f', '/data/TARFILES/test.ndt5.tgz', '--directory=/data/TARFILES/', '2020/06/02/ndt-567fj_1589322458_00000000000B9A17.json']\n",
      "['ndt-567fj_1589322458_00000000000B9A17.json']\n"
     ]
    }
   ],
   "source": [
    "def searchTar(uuids, tarFile):\n",
    "    \"\"\"Search for uuids in a tarfile, return file name if found\"\"\"\n",
    "    proc=subprocess.Popen([\"tar\", \"tf\", tarFile], stdout=subprocess.PIPE, text=True)\n",
    "    try:\n",
    "        outs, errs = proc.communicate(timeout=10)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        proc.kill()\n",
    "        outs, errs = proc.communicate()\n",
    "    res = []\n",
    "    for l in outs.split():\n",
    "        for uuid in uuids:\n",
    "            if uuid in l:\n",
    "                if Verbose:\n",
    "                    print (\"Found: \"+l)\n",
    "                res.append(l)\n",
    "    return res\n",
    "\n",
    "def TarExtractFile(tarFile, targetDir, files):\n",
    "    \"\"\"Extract files from tarFile into targetDir\n",
    "    \"\"\"\n",
    "    args=[\"tar\", \"--extract\", \"-f\", tarFile,  \"--directory=\"+TarDir, *files]\n",
    "    if UnitTest:\n",
    "        print (args)\n",
    "    subprocess.run(args).check_returncode()\n",
    "    for file in files:\n",
    "        os.replace(TarDir+file, targetDir+file.split('/')[-1])\n",
    "    # TODO: rmdir 2019/.... (empty)\n",
    "    return [f.split('/')[-1] for f in files]\n",
    "\n",
    "if UnitTest:\n",
    "    os.makedirs(DataDir+\"test/\", exist_ok=True)\n",
    "    print (T_UUIDs[0])\n",
    "    # ndt-m92kv_1573028939_0000000000056D7A\n",
    "    print (searchTar(['xxx'], TarDir+'test.ndt5.tgz'))\n",
    "    # None\n",
    "    T_ndt5_json=searchTar(T_UUIDs, TarDir+'test.ndt5.tgz')\n",
    "    # Found: 2019/12/28/ndt-m92kv_1573028939_0000000000056D78.json\n",
    "    print (T_ndt5_json)\n",
    "    # 2019/12/28/ndt-m92kv_1573028939_0000000000056D78.json\n",
    "    print (TarExtractFile(TarDir+'test.ndt5.tgz', DataDir+\"test/\", T_ndt5_json))\n",
    "    # ndt-m92kv_1573028939_0000000000056D78.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndt/pcap/2020/06/02 20200602T051452\n",
      "Available server-day pusher files: 53\n",
      "Trying: 10 ndt/pcap/2020/06/02/20200602T050112.639896Z-pcap-mlab1-sea02-ndt.tgz\n",
      "Found: 2020/06/02/ndt-567fj_1589322458_00000000000B9A17.pcap.gz\n",
      "Found: 2020/06/02/ndt-567fj_1589322458_00000000000B9A19.pcap.gz\n",
      "Extacting: 2020/06/02/ndt-567fj_1589322458_00000000000B9A17.pcap.gz 2020/06/02/ndt-567fj_1589322458_00000000000B9A19.pcap.gz\n",
      "['tar', '--extract', '-f', '/data/TARFILES/20200602T050112.639896Z-pcap-mlab1-sea02-ndt.tgz', '--directory=/data/TARFILES/', '2020/06/02/ndt-567fj_1589322458_00000000000B9A17.pcap.gz', '2020/06/02/ndt-567fj_1589322458_00000000000B9A19.pcap.gz']\n",
      "Trying: 9 ndt/pcap/2020/06/02/20200602T043707.696030Z-pcap-mlab1-sea02-ndt.tgz\n",
      "Trying: 11 ndt/pcap/2020/06/02/20200602T053114.773935Z-pcap-mlab1-sea02-ndt.tgz\n",
      "Found: 2020/06/02/ndt-567fj_1589322458_00000000000B9A29.pcap.gz\n",
      "Extacting: 2020/06/02/ndt-567fj_1589322458_00000000000B9A29.pcap.gz\n",
      "['tar', '--extract', '-f', '/data/TARFILES/20200602T053114.773935Z-pcap-mlab1-sea02-ndt.tgz', '--directory=/data/TARFILES/', '2020/06/02/ndt-567fj_1589322458_00000000000B9A29.pcap.gz']\n",
      "Trying: 12 ndt/pcap/2020/06/02/20200602T060556.149374Z-pcap-mlab1-sea02-ndt.tgz\n",
      "['2020/06/02/ndt-567fj_1589322458_00000000000B9A17.pcap.gz', '2020/06/02/ndt-567fj_1589322458_00000000000B9A19.pcap.gz', '2020/06/02/ndt-567fj_1589322458_00000000000B9A29.pcap.gz']\n"
     ]
    }
   ],
   "source": [
    "# New platform only\n",
    "\n",
    "\n",
    "def getPusherObject(TargetDir, UUIDs, shortname, timeHint, gcsDir):\n",
    "    \"\"\"\n",
    "    TargetDir - Results\n",
    "    UUIDs - List of UUIDs that we want\n",
    "    timeHint - test time stamp, to facilitate locating the data\n",
    "    gcsDir - Where to find the archive, w/o the bucket name\n",
    "    \"\"\"\n",
    "    blobs=listArchive(gcsDir)\n",
    "    blobs = [x for x in blobs if shortname in x]\n",
    "    if Verbose:\n",
    "        print (\"Available server-day pusher files:\", len(blobs))\n",
    "    otime = \"\"\n",
    "    ix = -1\n",
    "    for i, b in enumerate(blobs):\n",
    "        btime = parseTime(b)\n",
    "        if btime < otime:\n",
    "            print (\"Warning: non-monitonic timestamps %s>%s\"%(otime, time))\n",
    "        if btime <= timeHint:\n",
    "            ix = i\n",
    "        otime = btime\n",
    "    filelist=[]\n",
    "    for offset in [0, -1, 1, 2]:\n",
    "        if ix+offset >= 0 and ix+offset < len(blobs):\n",
    "            blob=blobs[ix+offset]\n",
    "            if Verbose:\n",
    "                print ('Trying:', ix+offset, blob)\n",
    "            tarFile=TarDir+blob.split('/')[-1]\n",
    "            fetchBlob(blob, tarFile)\n",
    "            fl=searchTar(UUIDs, tarFile)\n",
    "            if len(fl) > 0:\n",
    "                if Verbose:\n",
    "                    print('Extacting:',' '.join(fl))\n",
    "                TarExtractFile(tarFile, TargetDir, fl)\n",
    "                filelist.extend(fl)\n",
    "    return filelist\n",
    "\n",
    "\n",
    "if UnitTest:\n",
    "    T_pcapDir=parseDir(TtaskFile).replace('ndt5','pcap')\n",
    "    T_shortname=parseShortName(TtaskFile)  # mlab1-lhr04\n",
    "    T_testTime=parseTime(TtaskFile)\n",
    "    print(T_pcapDir, T_testTime)\n",
    "    \n",
    "    print(getPusherObject(DataDir+\"test/\", T_UUIDs, T_shortname, T_testTime, T_pcapDir));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UUIDs: ndt-m92kv_1573028939_0000000000056D7A ndt-m92kv_1573028939_0000000000056D78\n",
      "gcsNDTtaskFile: gs://archive-measurement-lab/ndt/ndt5/2019/12/28/20191228T080102.072817Z-ndt5-mlab1-lhr04-ndt.tgz\n",
      "mlab1-lhr04 20191228T080102 ndt/ndt5/2019/12/28\n",
      "Checking for ndt5 archives\n",
      "Available server-day pusher files: 12\n",
      "Trying: 3 ndt/ndt5/2019/12/28/20191228T080102.072817Z-ndt5-mlab1-lhr04-ndt.tgz\n",
      "Found: 2019/12/28/ndt-m92kv_1573028939_0000000000056D78.json\n",
      "Extacting: 2019/12/28/ndt-m92kv_1573028939_0000000000056D78.json\n",
      "['tar', '--extract', '-f', '/data/TARFILES/20191228T080102.072817Z-ndt5-mlab1-lhr04-ndt.tgz', '--directory=/data/TARFILES/', '2019/12/28/ndt-m92kv_1573028939_0000000000056D78.json']\n",
      "Trying: 2 ndt/ndt5/2019/12/28/20191228T060100.223473Z-ndt5-mlab1-lhr04-ndt.tgz\n",
      "Trying: 4 ndt/ndt5/2019/12/28/20191228T100102.654064Z-ndt5-mlab1-lhr04-ndt.tgz\n",
      "Trying: 5 ndt/ndt5/2019/12/28/20191228T120130.853831Z-ndt5-mlab1-lhr04-ndt.tgz\n",
      "Found 1 ndt5 archives\n",
      "Checking for ndt7 archives\n",
      "Available server-day pusher files: 0\n",
      "Checking for pcap archives\n",
      "Available server-day pusher files: 99\n",
      "Trying: 18 ndt/pcap/2019/12/28/20191228T074635.485037Z-pcap-mlab1-lhr04-ndt.tgz\n",
      "Found: 2019/12/28/ndt-m92kv_1573028939_0000000000056D78.pcap.gz\n",
      "Found: 2019/12/28/ndt-m92kv_1573028939_0000000000056D7A.pcap.gz\n",
      "Extacting: 2019/12/28/ndt-m92kv_1573028939_0000000000056D78.pcap.gz 2019/12/28/ndt-m92kv_1573028939_0000000000056D7A.pcap.gz\n",
      "['tar', '--extract', '-f', '/data/TARFILES/20191228T074635.485037Z-pcap-mlab1-lhr04-ndt.tgz', '--directory=/data/TARFILES/', '2019/12/28/ndt-m92kv_1573028939_0000000000056D78.pcap.gz', '2019/12/28/ndt-m92kv_1573028939_0000000000056D7A.pcap.gz']\n",
      "Trying: 17 ndt/pcap/2019/12/28/20191228T070009.058070Z-pcap-mlab1-lhr04-ndt.tgz\n",
      "Trying: 19 ndt/pcap/2019/12/28/20191228T080522.979468Z-pcap-mlab1-lhr04-ndt.tgz\n",
      "Trying: 20 ndt/pcap/2019/12/28/20191228T082536.204542Z-pcap-mlab1-lhr04-ndt.tgz\n",
      "Found 2 pcap archives\n",
      "Checking for tcpinfo archives\n",
      "Available server-day pusher files: 17\n",
      "Trying: 3 ndt/tcpinfo/2019/12/28/20191228T080020.563296Z-tcpinfo-mlab1-lhr04-ndt.tgz\n",
      "Found: 2019/12/28/ndt-m92kv_1573028939_0000000000056D78.00000.jsonl.zst\n",
      "Found: 2019/12/28/ndt-m92kv_1573028939_0000000000056D7A.00000.jsonl.zst\n",
      "Extacting: 2019/12/28/ndt-m92kv_1573028939_0000000000056D78.00000.jsonl.zst 2019/12/28/ndt-m92kv_1573028939_0000000000056D7A.00000.jsonl.zst\n",
      "['tar', '--extract', '-f', '/data/TARFILES/20191228T080020.563296Z-tcpinfo-mlab1-lhr04-ndt.tgz', '--directory=/data/TARFILES/', '2019/12/28/ndt-m92kv_1573028939_0000000000056D78.00000.jsonl.zst', '2019/12/28/ndt-m92kv_1573028939_0000000000056D7A.00000.jsonl.zst']\n",
      "Trying: 2 ndt/tcpinfo/2019/12/28/20191228T060017.042393Z-tcpinfo-mlab1-lhr04-ndt.tgz\n",
      "Trying: 4 ndt/tcpinfo/2019/12/28/20191228T100023.800221Z-tcpinfo-mlab1-lhr04-ndt.tgz\n",
      "Trying: 5 ndt/tcpinfo/2019/12/28/20191228T112721.525295Z-tcpinfo-mlab1-lhr04-ndt.tgz\n",
      "Found 2 tcpinfo archives\n",
      "Checking for traceeroute archives\n",
      "Available server-day pusher files: 0\n",
      "Checking for web100 archives\n",
      "Available server-day pusher files: 0\n",
      "{'ndt5': ['2019/12/28/ndt-m92kv_1573028939_0000000000056D78.json'], 'pcap': ['2019/12/28/ndt-m92kv_1573028939_0000000000056D78.pcap.gz', '2019/12/28/ndt-m92kv_1573028939_0000000000056D7A.pcap.gz'], 'tcpinfo': ['2019/12/28/ndt-m92kv_1573028939_0000000000056D78.00000.jsonl.zst', '2019/12/28/ndt-m92kv_1573028939_0000000000056D7A.00000.jsonl.zst']}\n"
     ]
    }
   ],
   "source": [
    "# prototype main\n",
    "\n",
    "\n",
    "def GatherRawNDT5(uuid):\n",
    "    \"\"\"With just (any) UUID, gather all test data\n",
    "    \"\"\"\n",
    "    NDTtaskFile, UUIDs = getTestDetails(uuid)\n",
    "\n",
    "    if NDTtaskFile == '':\n",
    "        print (\"Failed to find Archive\")\n",
    "    if Verbose:\n",
    "        print('UUIDs: '+' '.join(UUIDs))\n",
    "        print(\"gcsNDTtaskFile: \"+NDTtaskFile)\n",
    "\n",
    "\n",
    "    # Make the target dir after the lookup to avoid debris from failures\n",
    "    # Stabilize UUIDs\n",
    "    # UUIDs=sorted(UUIDs)\n",
    "    if UUIDs[0] != uuid:\n",
    "        uuid = UUIDs[0]\n",
    "        print ('Updating base UUID (probably the control connection):',uuid)\n",
    "    TargetDir = DataDir+uuid+'/'\n",
    "    os.makedirs(TargetDir, exist_ok=True)\n",
    "    \n",
    "    # Guess pcap dir and search for likely tar files\n",
    "    shortname=parseShortName(NDTtaskFile)  # mlab1-lhr04\n",
    "    timeHint=parseTime(NDTtaskFile)\n",
    "    gcsDir=parseDir(NDTtaskFile)\n",
    "    print (shortname, timeHint, gcsDir)\n",
    "    ret={}\n",
    "    dataSets=['ndt5','ndt7','pcap','tcpinfo','traceeroute','web100']\n",
    "    for d in dataSets:\n",
    "        print (\"Checking for %s archives\"%d)\n",
    "        r=getPusherObject(TargetDir, UUIDs, shortname, timeHint, gcsDir.replace('ndt5',d))\n",
    "        if r is not None and len(r) > 0:\n",
    "            print ('Found',len(r), d,'archives')\n",
    "            ret[d]=r\n",
    "    return(ret)\n",
    "\n",
    "if UnitTest:\n",
    "    r=GatherRawNDT5(UUID2)\n",
    "    print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r=GatherRawNDT5(UUID3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
